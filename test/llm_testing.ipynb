{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3276f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "\n",
    "# Force reload the .env file\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "# print(\"Current API Key:\", os.getenv('GOOGLE_API_KEY'))\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-lite\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None, \n",
    "    max_retries=3,\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "\n",
    "# step2 : Output Parser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# step 3: Structured output\n",
    "\n",
    "class MobileReview(BaseModel):\n",
    "    phone_model: str = Field(description=\"The model of the phone\")\n",
    "    rating: float = Field(description=\"Overall rating out of 5\")\n",
    "    pros: List[str] = Field(description=\"List of positive aspects\")\n",
    "    cos: List[str] = Field(description=\"List of negative aspects\")\n",
    "    summary: str = Field(description=\"Brief summary of the review\")\n",
    "\n",
    "review_text = \"\"\"\n",
    "Just got my hands on the new Galaxy S21 and wow, this thing is slick! The screen is gorgeous,\n",
    "colors pop like crazy. Camera's insane too, especially at night - my Insta game's never been\n",
    "stronger. Battery life's solid, lasts me all day no problem.\n",
    "Not gonna lie though, it's pretty pricey. And what's with ditching the charger? C'mon Samsung.\n",
    "Also, still getting used to the new button layout, keep hitting Bixby by mistake.\n",
    "Overall, I'd say it's a solid 8 out of 10. Great phone, but a few annoying quirks keep it from\n",
    "being perfect. If you're due for an upgrade, definitely worth checking out!\n",
    "\"\"\"\n",
    "\n",
    "# structured_llm = llm.with_structured_output(\n",
    "#     MobileReview,\n",
    "# )\n",
    "# output = structured_llm.invoke(review_text)\n",
    "# print(output)\n",
    "# print(output.pros)\n",
    "\n",
    "# step 4: Prompt Template\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Tell me a a short remark about {input} and give your  thinkings about{input}\"\n",
    ")\n",
    "chain = prompt  | llm | output_parser\n",
    "# result = chain.invoke({\"input\": \"Naruto Uzumaki\"})\n",
    "# print(result)\n",
    "\n",
    "# step 5: LLM Message\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant the help answer my question accurately and succintly and yet concisely!\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"Tell me about Naruto's childhood and what makes him so obsessed with becoming Hokage.\"\n",
    "    )\n",
    "]\n",
    "# response = llm.invoke(messages)\n",
    "# print(response.content)\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"Tell me about {input}\")\n",
    "])\n",
    "chain = template | llm | output_parser\n",
    "result = chain.invoke({\"input\": {\"Naruto's Nindo, his ninja way\"}})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8257b26f",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60639943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-lite\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None, \n",
    "    max_retries=3,\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f7a9400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GoogleGenerativeAIEmbeddings(client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x796ec81bbce0>, model='models/text-embedding-004', task_type=None, google_api_key=SecretStr('**********'), credentials=None, client_options=None, transport=None, request_options=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from pymongo import MongoClient\n",
    "from pymongo.operations import SearchIndexModel\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "import logging\n",
    "\n",
    "gemini_embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/text-embedding-004\",\n",
    "    google_api_key=GOOGLE_API_KEY\n",
    ")\n",
    "gemini_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93757d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGODB_ATLAS_CLUSTER_URI = os.getenv(\"MONGODB_ATLAS_CLUSTER_URI\")\n",
    "client = MongoClient(\n",
    "    MONGODB_ATLAS_CLUSTER_URI\n",
    ")\n",
    "DB_NAME = \"RAG-Chatbot-Cluster\"\n",
    "COLLECTION_NAME = \"RAG-Chatbot-Collection-Test\"\n",
    "ATLAS_VECTOR_SEARCH_INDEX_NAME = \"RAG-Chatbot-Index-Test\"\n",
    "\n",
    "MONGODB_COLLECTION = client[DB_NAME][COLLECTION_NAME]\n",
    "\n",
    "vector_store = MongoDBAtlasVectorSearch(\n",
    "    collection=MONGODB_COLLECTION,\n",
    "    embedding=gemini_embeddings,\n",
    "    index_name=ATLAS_VECTOR_SEARCH_INDEX_NAME,\n",
    "    relevance_score_fn=\"cosine\"\n",
    ")\n",
    "\n",
    "def initialize_vector_store():\n",
    "    \"\"\"Initialize the MongoDB collection and verify the vector search index.\"\"\"\n",
    "    try:\n",
    "        # Verify MongoDB connection\n",
    "        client.server_info()  # Raises an exception if connection fails\n",
    "        logging.info(\"MongoDB connection established successfully\")\n",
    "\n",
    "        # Check if collection exists\n",
    "        if COLLECTION_NAME not in client[DB_NAME].list_collection_names():\n",
    "            client[DB_NAME].create_collection(COLLECTION_NAME)\n",
    "            logging.info(f\"Created collection {COLLECTION_NAME}\")\n",
    "        else:\n",
    "            logging.info(f\"Collection {COLLECTION_NAME} already exists\")\n",
    "\n",
    "\n",
    "        # Note: Vector search index must be created in MongoDB Atlas UI or via API\n",
    "        logging.info(f\"Ensure vector search index '{ATLAS_VECTOR_SEARCH_INDEX_NAME}' is configured in MongoDB Atlas for collection {COLLECTION_NAME}\")\n",
    "        create_index()\n",
    "        # vector_store.create_vector_search_index(\n",
    "        #     dimensions=768,\n",
    "        #     filters=[{\"type\":\"filter\", \"path\": \"source\"}],\n",
    "        #     update=True\n",
    "        # )\n",
    "        # Test vector store by adding a dummy document\n",
    "        dummy_doc = Document(page_content=\"Test document\", metadata={\"file_id\": 0})\n",
    "        vector_store.add_documents([dummy_doc])\n",
    "        logging.info(\"Added test document to vector store\")\n",
    "\n",
    "        # Log the inserted document to inspect its structure\n",
    "        inserted_doc = vector_store._collection.find_one({\"file_id\": 0})\n",
    "        if inserted_doc:\n",
    "            logging.info(f\"Inserted test document: {inserted_doc.get('file_id')}\")\n",
    "        else:\n",
    "            logging.error(\"Test document not found after insertion\")\n",
    "\n",
    "        # Delete the test document\n",
    "        result = vector_store._collection.delete_one({\"file_id\": 0})\n",
    "        if result.deleted_count > 0:\n",
    "            logging.info(\"Successfully deleted test document\")\n",
    "        else:\n",
    "            logging.warning(\"No test document was deleted; check document structure or query\")\n",
    "\n",
    "        # Verify deletion\n",
    "        remaining_doc = vector_store._collection.find_one({\".file_id\": 0})\n",
    "        if remaining_doc:\n",
    "            logging.error(f\"Test document still exists after deletion attempt: {remaining_doc}\")\n",
    "        else:\n",
    "            logging.info(\"Confirmed test document was deleted\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to initialize vector store: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def create_index():\n",
    "    search_index_model = SearchIndexModel(\n",
    "                definition={\n",
    "                    \"mappings\": {\n",
    "                        \"dynamic\": True,\n",
    "                        \"fields\": {\n",
    "                            \"embedding\": {  # Correct structure: field name as key\n",
    "                                \"type\": \"knnVector\",\n",
    "                                \"dimensions\": 768,\n",
    "                                \"similarity\": \"cosine\"\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                name=ATLAS_VECTOR_SEARCH_INDEX_NAME,\n",
    "            )\n",
    "    \n",
    "    result = MONGODB_COLLECTION.create_search_index(model=search_index_model)\n",
    "    logging.info(f\"Succesfully creating Atlas Search Index: {result}\")\n",
    "\n",
    "\n",
    "def delete_collection():\n",
    "    \"\"\"Delete the entire MongoDB collection.\"\"\"\n",
    "    try:\n",
    "        client[DB_NAME].drop_collection(COLLECTION_NAME)\n",
    "        logging.info(f\"Successfully deleted collection {COLLECTION_NAME}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error deleting collection {COLLECTION_NAME}: {str(e)}\")\n",
    "        return False\n",
    "    \n",
    "initialize_vector_store()\n",
    "# create_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89977780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RAG-Chatbot-Collection-Test']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.server_info()\n",
    "client[DB_NAME].list_collection_names()\n",
    "# delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ae72b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['6808793bce177c45570f34ee',\n",
       " '6808793bce177c45570f34ef',\n",
       " '6808793bce177c45570f34f0',\n",
       " '6808793bce177c45570f34f1',\n",
       " '6808793bce177c45570f34f2',\n",
       " '6808793bce177c45570f34f3',\n",
       " '6808793bce177c45570f34f4',\n",
       " '6808793bce177c45570f34f5',\n",
       " '6808793bce177c45570f34f6',\n",
       " '6808793bce177c45570f34f7',\n",
       " '6808793bce177c45570f34f8',\n",
       " '6808793bce177c45570f34f9',\n",
       " '6808793bce177c45570f34fa',\n",
       " '6808793bce177c45570f34fb',\n",
       " '6808793bce177c45570f34fc',\n",
       " '6808793bce177c45570f34fd',\n",
       " '6808793bce177c45570f34fe',\n",
       " '6808793bce177c45570f34ff',\n",
       " '6808793bce177c45570f3500',\n",
       " '6808793bce177c45570f3501',\n",
       " '6808793bce177c45570f3502',\n",
       " '6808793bce177c45570f3503',\n",
       " '6808793bce177c45570f3504',\n",
       " '6808793bce177c45570f3505',\n",
       " '6808793bce177c45570f3506',\n",
       " '6808793bce177c45570f3507',\n",
       " '6808793bce177c45570f3508',\n",
       " '6808793bce177c45570f3509',\n",
       " '6808793bce177c45570f350a',\n",
       " '6808793bce177c45570f350b',\n",
       " '6808793bce177c45570f350c',\n",
       " '6808793bce177c45570f350d',\n",
       " '6808793bce177c45570f350e',\n",
       " '6808793bce177c45570f350f',\n",
       " '6808793bce177c45570f3510',\n",
       " '6808793bce177c45570f3511',\n",
       " '6808793bce177c45570f3512',\n",
       " '6808793bce177c45570f3513',\n",
       " '6808793bce177c45570f3514',\n",
       " '6808793bce177c45570f3515',\n",
       " '6808793bce177c45570f3516',\n",
       " '6808793bce177c45570f3517',\n",
       " '6808793bce177c45570f3518',\n",
       " '6808793bce177c45570f3519',\n",
       " '6808793bce177c45570f351a',\n",
       " '6808793bce177c45570f351b',\n",
       " '6808793bce177c45570f351c',\n",
       " '6808793bce177c45570f351d',\n",
       " '6808793bce177c45570f351e',\n",
       " '6808793bce177c45570f351f',\n",
       " '6808793bce177c45570f3520',\n",
       " '6808793bce177c45570f3521',\n",
       " '6808793bce177c45570f3522',\n",
       " '6808793bce177c45570f3523',\n",
       " '6808793bce177c45570f3524',\n",
       " '6808793bce177c45570f3525',\n",
       " '6808793bce177c45570f3526',\n",
       " '6808793bce177c45570f3527',\n",
       " '6808793bce177c45570f3528',\n",
       " '6808793bce177c45570f3529',\n",
       " '6808793bce177c45570f352a',\n",
       " '6808793bce177c45570f352b',\n",
       " '6808793bce177c45570f352c',\n",
       " '6808793bce177c45570f352d',\n",
       " '6808793bce177c45570f352e',\n",
       " '6808793bce177c45570f352f']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "from bson.objectid import ObjectId\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(len(splits))\n",
    "for split in splits:\n",
    "            # add file id to the metadata of each split\n",
    "    split.metadata['file_id'] = 0\n",
    "        \n",
    "        # add the document chunks to the vector store\n",
    "vector_store.add_documents(splits)\n",
    "# vector_store.add_documents(documents=splits, ids=[str(uuid4) for _ in range(len(splits))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e3650e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(['6808793bce177c45570f34ee',\n",
    " '6808793bce177c45570f34ef',\n",
    " '6808793bce177c45570f34f0',\n",
    " '6808793bce177c45570f34f1',\n",
    " '6808793bce177c45570f34f2',\n",
    " '6808793bce177c45570f34f3',\n",
    " '6808793bce177c45570f34f4',\n",
    " '6808793bce177c45570f34f5',\n",
    " '6808793bce177c45570f34f6',\n",
    " '6808793bce177c45570f34f7',\n",
    " '6808793bce177c45570f34f8',\n",
    " '6808793bce177c45570f34f9',\n",
    " '6808793bce177c45570f34fa',\n",
    " '6808793bce177c45570f34fb',\n",
    " '6808793bce177c45570f34fc',\n",
    " '6808793bce177c45570f34fd',\n",
    " '6808793bce177c45570f34fe',\n",
    " '6808793bce177c45570f34ff',\n",
    " '6808793bce177c45570f3500',\n",
    " '6808793bce177c45570f3501',\n",
    " '6808793bce177c45570f3502',\n",
    " '6808793bce177c45570f3503',\n",
    " '6808793bce177c45570f3504',\n",
    " '6808793bce177c45570f3505',\n",
    " '6808793bce177c45570f3506',\n",
    " '6808793bce177c45570f3507',\n",
    " '6808793bce177c45570f3508',\n",
    " '6808793bce177c45570f3509',\n",
    " '6808793bce177c45570f350a',\n",
    " '6808793bce177c45570f350b',\n",
    " '6808793bce177c45570f350c',\n",
    " '6808793bce177c45570f350d',\n",
    " '6808793bce177c45570f350e',\n",
    " '6808793bce177c45570f350f',\n",
    " '6808793bce177c45570f3510',\n",
    " '6808793bce177c45570f3511',\n",
    " '6808793bce177c45570f3512',\n",
    " '6808793bce177c45570f3513',\n",
    " '6808793bce177c45570f3514',\n",
    " '6808793bce177c45570f3515',\n",
    " '6808793bce177c45570f3516',\n",
    " '6808793bce177c45570f3517',\n",
    " '6808793bce177c45570f3518',\n",
    " '6808793bce177c45570f3519',\n",
    " '6808793bce177c45570f351a',\n",
    " '6808793bce177c45570f351b',\n",
    " '6808793bce177c45570f351c',\n",
    " '6808793bce177c45570f351d',\n",
    " '6808793bce177c45570f351e',\n",
    " '6808793bce177c45570f351f',\n",
    " '6808793bce177c45570f3520',\n",
    " '6808793bce177c45570f3521',\n",
    " '6808793bce177c45570f3522',\n",
    " '6808793bce177c45570f3523',\n",
    " '6808793bce177c45570f3524',\n",
    " '6808793bce177c45570f3525',\n",
    " '6808793bce177c45570f3526',\n",
    " '6808793bce177c45570f3527',\n",
    " '6808793bce177c45570f3528',\n",
    " '6808793bce177c45570f3529',\n",
    " '6808793bce177c45570f352a',\n",
    " '6808793bce177c45570f352b',\n",
    " '6808793bce177c45570f352c',\n",
    " '6808793bce177c45570f352d',\n",
    " '6808793bce177c45570f352e',\n",
    " '6808793bce177c45570f352f']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d715b00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['_id', 'text', 'embedding', 'source', 'file_id'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectId('6808793bce177c45570f34ee')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = vector_store._collection.find({\"_id\": ObjectId('6808793bce177c45570f34ee')})\n",
    "methods = MONGODB_COLLECTION.find_one().keys()\n",
    "print(methods)\n",
    "res.to_list()[0].get('_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d09fc84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition is the process of breaking down a complex task into smaller, simpler steps. This is often done to improve model performance on complex tasks. It can be achieved through techniques like Chain of Thought and Tree of Thoughts.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vector_store.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb70dfbc",
   "metadata": {},
   "source": [
    "##  []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
