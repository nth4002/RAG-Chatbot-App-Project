{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "699ec883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only PDF and DOCX files are supported. Skipping txt.\n",
      "[INFO] Split the documents into 2844 chunks.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import (\n",
    "    PyPDFLoader,\n",
    "    Docx2txtLoader,\n",
    ")\n",
    "from langchain_text_splitters import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "from typing import List\n",
    "from langchain_core.documents import (\n",
    "    Document,\n",
    ")\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import os\n",
    "import random\n",
    "\n",
    "def load_documents(folder_path: str) -> List[Document]:\n",
    "    documents = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(os.path.join(folder_path, filename))\n",
    "        elif filename.endswith(\".docx\"):\n",
    "            loader = Docx2txtLoader(os.path.join(folder_path, filename))\n",
    "        else:\n",
    "            print(f\"Only PDF and DOCX files are supported. Skipping {filename}.\")\n",
    "            continue\n",
    "        documents.extend(loader.load())\n",
    "    return documents\n",
    "\n",
    "folder_path = os.path.abspath(\"./../docs\")\n",
    "documents = load_documents(folder_path)\n",
    "# print(f\"Loader {len(documents)} documents from the folder '{folder_path}'\")\n",
    "\n",
    "\n",
    "# step 2: splitting document\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_documents(documents=documents)\n",
    "print(f\"[INFO] Split the documents into {len(texts)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72926a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-google-genai 2.1.3 requires pydantic<3,>=2, but you have pydantic 1.10.21 which is incompatible.\n",
      "argilla 2.8.0 requires pydantic<3.0.0,>=2.6.0, but you have pydantic 1.10.21 which is incompatible.\n",
      "unstructured-client 0.33.0 requires pydantic>=2.11.2, but you have pydantic 1.10.21 which is incompatible.\n",
      "unstructured-client 0.33.0 requires pypdf>=4.0, but you have pypdf 3.8.1 which is incompatible.\n",
      "pydantic-settings 2.8.1 requires pydantic>=2.7.0, but you have pydantic 1.10.21 which is incompatible.\n",
      "langchain-core 0.3.52 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.10.21 which is incompatible.\n",
      "langchain-google-vertexai 2.0.20 requires pydantic<3.0,>=2.9, but you have pydantic 1.10.21 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Failed to build installable wheels for some pyproject.toml based projects (pygptj)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.0.173 requires pydantic<2,>=1, but you have pydantic 2.11.3 which is incompatible.\n",
      "unstructured-client 0.33.0 requires pypdf>=4.0, but you have pypdf 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -Uqqq pip --progress-bar off\n",
    "!pip install -qqq openai==0.27.4 --progress-bar off\n",
    "!pip install -Uqqq watermark==2.3.1 --progress-bar off\n",
    "!pip install -qqq langchain==0.0.173 --progress-bar off\n",
    "!pip install -qqq chromadb==0.3.23 --progress-bar off\n",
    "!pip install -qqq pypdf==3.8.1 --progress-bar off\n",
    "!pip install -qqq pygpt4all==1.1.0 --progress-bar off\n",
    "!pip install -qqq pdf2image==1.16.3 --progress-bar off\n",
    "!pip install -Uqqq tiktoken==0.3.3 --progress-bar off\n",
    "!pip install -Uqqq unstructured[local-inference]==0.5.12 --progress-bar off\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eca53096",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File path /home/phucuy2025/RAG-Chatbot/docs/Lich su 11.pdf is not a valid file or url",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Chuyển file PDF về dạng text\u001b[39;00m\n\u001b[32m      4\u001b[39m file_path   = \u001b[33m\"\u001b[39m\u001b[33m/home/phucuy2025/RAG-Chatbot/docs/Lich su 11.pdf\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m pdf_loader = \u001b[43mPyPDFLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m pdf_pages = pdf_loader.load()\n\u001b[32m      7\u001b[39m pdf_pages\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/RAG-Chatbot/venv/lib/python3.12/site-packages/langchain_community/document_loaders/pdf.py:281\u001b[39m, in \u001b[36mPyPDFLoader.__init__\u001b[39m\u001b[34m(self, file_path, password, headers, extract_images, mode, images_parser, images_inner_format, pages_delimiter, extraction_mode, extraction_kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    239\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    240\u001b[39m     file_path: Union[\u001b[38;5;28mstr\u001b[39m, PurePath],\n\u001b[32m   (...)\u001b[39m\u001b[32m    250\u001b[39m     extraction_kwargs: Optional[\u001b[38;5;28mdict\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    251\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    252\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Initialize with a file path.\u001b[39;00m\n\u001b[32m    253\u001b[39m \n\u001b[32m    254\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    279\u001b[39m \u001b[33;03m        `aload` methods to retrieve parsed documents with content and metadata.\u001b[39;00m\n\u001b[32m    280\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m281\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28mself\u001b[39m.parser = PyPDFParser(\n\u001b[32m    283\u001b[39m         password=password,\n\u001b[32m    284\u001b[39m         mode=mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    290\u001b[39m         extraction_kwargs=extraction_kwargs,\n\u001b[32m    291\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/RAG-Chatbot/venv/lib/python3.12/site-packages/langchain_community/document_loaders/pdf.py:140\u001b[39m, in \u001b[36mBasePDFLoader.__init__\u001b[39m\u001b[34m(self, file_path, headers)\u001b[39m\n\u001b[32m    138\u001b[39m         \u001b[38;5;28mself\u001b[39m.file_path = \u001b[38;5;28mstr\u001b[39m(temp_pdf)\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isfile(\u001b[38;5;28mself\u001b[39m.file_path):\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mFile path \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m is not a valid file or url\u001b[39m\u001b[33m\"\u001b[39m % \u001b[38;5;28mself\u001b[39m.file_path)\n",
      "\u001b[31mValueError\u001b[39m: File path /home/phucuy2025/RAG-Chatbot/docs/Lich su 11.pdf is not a valid file or url"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader, PyPDFLoader\n",
    "from  langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# Chuyển file PDF về dạng text\n",
    "file_path   = \"/home/phucuy2025/RAG-Chatbot/docs/Lich su 11.pdf\"\n",
    "pdf_loader = PyPDFLoader(file_path)\n",
    "pdf_pages = pdf_loader.load()\n",
    "pdf_pages\n",
    "# Text Splitters\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=64)\n",
    "texts = text_splitter.split_documents(pdf_pages)\n",
    "len(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27782fed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'open_filename' from 'pdfminer.utils' (/home/phucuy2025/RAG-Chatbot/venv/lib/python3.12/site-packages/pdfminer/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     40\u001b[39m file_path   = \u001b[33m\"\u001b[39m\u001b[33m/home/phucuy2025/RAG-Chatbot/docs/cac_trieu_dai_VietNam.pdf\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     41\u001b[39m file_path_2 = \u001b[33m\"\u001b[39m\u001b[33m/home/phucuy2025/RAG-Chatbot/docs/Human-Nutrition-2020-Edition-1598491699.pdf\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m splits = \u001b[43mload_and_split_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(splits))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mload_and_split_document\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file_path.endswith(\u001b[33m\"\u001b[39m\u001b[33m.pdf\u001b[39m\u001b[33m\"\u001b[39m):\\\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Chuyển file PDF về dạng text\u001b[39;00m\n\u001b[32m     20\u001b[39m     pdf_loader = UnstructuredPDFLoader(file_path)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     pdf_pages = \u001b[43mpdf_loader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_and_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m# loader = PyPDFLoader(file_path)\u001b[39;00m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPDF here\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/RAG-Chatbot/venv/lib/python3.12/site-packages/langchain_core/document_loaders/base.py:66\u001b[39m, in \u001b[36mBaseLoader.load_and_split\u001b[39m\u001b[34m(self, text_splitter)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     65\u001b[39m     _text_splitter = text_splitter\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m docs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _text_splitter.split_documents(docs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/RAG-Chatbot/venv/lib/python3.12/site-packages/langchain_core/document_loaders/base.py:32\u001b[39m, in \u001b[36mBaseLoader.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[32m     31\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/RAG-Chatbot/venv/lib/python3.12/site-packages/langchain_community/document_loaders/unstructured.py:107\u001b[39m, in \u001b[36mUnstructuredBaseLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlazy_load\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[Document]:\n\u001b[32m    106\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load file.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     elements = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28mself\u001b[39m._post_process_elements(elements)\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33melements\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/RAG-Chatbot/venv/lib/python3.12/site-packages/langchain_community/document_loaders/pdf.py:92\u001b[39m, in \u001b[36mUnstructuredPDFLoader._get_elements\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_elements\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m partition_pdf\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m partition_pdf(filename=\u001b[38;5;28mself\u001b[39m.file_path, **\u001b[38;5;28mself\u001b[39m.unstructured_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/RAG-Chatbot/venv/lib/python3.12/site-packages/unstructured/partition/pdf.py:15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwrapt\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayout\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LTContainer, LTImage, LTItem, LTTextBox\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m open_filename\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpi_heif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m register_heif_opener\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image \u001b[38;5;28;01mas\u001b[39;00m PILImage\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'open_filename' from 'pdfminer.utils' (/home/phucuy2025/RAG-Chatbot/venv/lib/python3.12/site-packages/pdfminer/utils.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader, UnstructuredHTMLLoader, UnstructuredPDFLoader\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from pymongo import MongoClient\n",
    "\n",
    "import os\n",
    "import logging\n",
    "\n",
    "text_splitters = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, length_function=len)\n",
    "\n",
    "def load_and_split_document(file_path: str) -> List[Document]:\n",
    "    if file_path.endswith(\".pdf\"):\\\n",
    "    # Chuyển file PDF về dạng text\n",
    "        pdf_loader = UnstructuredPDFLoader(file_path)\n",
    "        pdf_pages = pdf_loader.load_and_split()\n",
    "\n",
    "        # loader = PyPDFLoader(file_path)\n",
    "        print(\"PDF here\")\n",
    "    elif file_path.endswith('.docx'):\n",
    "        loader = Docx2txtLoader(file_path)\n",
    "    elif file_path.endswith('.html'):\n",
    "        loader = UnstructuredHTMLLoader(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type: {file_path}\")\n",
    "    \n",
    "    documents = loader.load()\n",
    "    # print(documents)\n",
    "    return text_splitters.split_documents(pdf_pages)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Indexing documents\n",
    "\"\"\"\n",
    "# file_path   = \"/home/phucuy2025/RAG-Chatbot/docs/cac_trieu_dai_VietNam.pdf\"\n",
    "file_path_2 = \"/home/phucuy2025/RAG-Chatbot/docs/Human-Nutrition-2020-Edition-1598491699.pdf\"\n",
    "splits = load_and_split_document(file_path)\n",
    "print(len(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef88b67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/phucuy2025/RAG-Chatbot/docs/cac_trieu_dai_VietNam.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "396"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "\n",
    "file_path = \"/home/phucuy2025/RAG-Chatbot/docs/LS11.pdf\"\n",
    "file_path = \"/home/phucuy2025/RAG-Chatbot/docs/ong-gia-va-bien-ca-ernest-hemingway.pdf\"\n",
    "file_path = \"/home/phucuy2025/RAG-Chatbot/docs/cac_trieu_dai_VietNam.pdf\"\n",
    "# file_path = \"/home/phucuy2025/RAG-Chatbot/docs/Vietnam Study_1.pdf\"\n",
    "print(file_path)\n",
    "\n",
    "loader = PDFPlumberLoader(file_path)\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca22123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[10].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0fe622a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Page 1 is copyable.\n",
      "✅ Page 2 is copyable.\n",
      "✅ Page 3 is copyable.\n",
      "✅ Page 4 is copyable.\n",
      "✅ Page 5 is copyable.\n",
      "✅ Page 6 is copyable.\n",
      "✅ Page 7 is copyable.\n",
      "✅ Page 8 is copyable.\n",
      "✅ Page 9 is copyable.\n",
      "✅ Page 10 is copyable.\n",
      "✅ Page 11 is copyable.\n",
      "✅ Page 12 is copyable.\n",
      "✅ Page 13 is copyable.\n",
      "✅ Page 14 is copyable.\n",
      "✅ Page 15 is copyable.\n",
      "✅ Page 16 is copyable.\n",
      "✅ Page 17 is copyable.\n",
      "✅ Page 18 is copyable.\n",
      "✅ Page 19 is copyable.\n",
      "✅ Page 20 is copyable.\n",
      "✅ Page 21 is copyable.\n",
      "✅ Page 22 is copyable.\n",
      "✅ Page 23 is copyable.\n",
      "✅ Page 24 is copyable.\n",
      "✅ Page 25 is copyable.\n",
      "✅ Page 26 is copyable.\n",
      "✅ Page 27 is copyable.\n",
      "✅ Page 28 is copyable.\n",
      "✅ Page 29 is copyable.\n",
      "✅ Page 30 is copyable.\n",
      "✅ Page 31 is copyable.\n",
      "✅ Page 32 is copyable.\n",
      "✅ Page 33 is copyable.\n",
      "✅ Page 34 is copyable.\n",
      "✅ Page 35 is copyable.\n",
      "✅ Page 36 is copyable.\n",
      "✅ Page 37 is copyable.\n",
      "✅ Page 38 is copyable.\n",
      "✅ Page 39 is copyable.\n",
      "✅ Page 40 is copyable.\n",
      "✅ Page 41 is copyable.\n",
      "✅ Page 42 is copyable.\n",
      "✅ Page 43 is copyable.\n",
      "✅ Page 44 is copyable.\n",
      "✅ Page 45 is copyable.\n",
      "✅ Page 46 is copyable.\n",
      "✅ Page 47 is copyable.\n",
      "✅ Page 48 is copyable.\n",
      "✅ Page 49 is copyable.\n",
      "✅ Page 50 is copyable.\n",
      "✅ Page 51 is copyable.\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def is_pdf_page_copyable(file_path):\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        length = len(pdf.pages)\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text()\n",
    "            if text and text.strip():  # If there's any meaningful text\n",
    "                print(f\"✅ Page {i+1} is copyable.\")\n",
    "            else:\n",
    "                print(f\"❌ Page {i+1} is NOT copyable. Possibly scanned or has weird encoding.\")\n",
    "                break\n",
    "            \n",
    "# file_path = \"/home/phucuy2025/RAG-Chatbot/docs/LS11.pdf\"\n",
    "file_path = \"/home/phucuy2025/RAG-Chatbot/docs/ong-gia-va-bien-ca-ernest-hemingway.pdf\"\n",
    "# file_path = \"/home/phucuy2025/RAG-Chatbot/docs/cac_trieu_dai_VietNam.pdf\"\n",
    "\n",
    "\n",
    "is_pdf_page_copyable(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf4f22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "\n",
    "website_link = 'https://apidog.com/vi/blog/rag-deepseek-r1-ollama-vi/'\n",
    "# website_link = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(website_link,),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "print(len(all_splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e98111e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28mprint\u001b[39m(text[:\u001b[32m1000\u001b[39m])  \u001b[38;5;66;03m# preview\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Run it\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/asyncio/runners.py:190\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug, loop_factory)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[32m    162\u001b[39m \n\u001b[32m    163\u001b[39m \u001b[33;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    186\u001b[39m \u001b[33;03m    asyncio.run(main())\u001b[39;00m\n\u001b[32m    187\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m events._get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    189\u001b[39m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    191\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug, loop_factory=loop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m runner.run(main)\n",
      "\u001b[31mRuntimeError\u001b[39m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "async def fetch_rendered_html(url):\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(url)\n",
    "        await page.wait_for_load_state('networkidle')\n",
    "        content = await page.content()\n",
    "        await browser.close()\n",
    "        return content\n",
    "\n",
    "async def main():\n",
    "    url = \"https://apidog.com/vi/blog/rag-deepseek-r1-ollama-vi/\"\n",
    "    html = await fetch_rendered_html(url)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    text = soup.get_text()\n",
    "    print(text[:1000])  # preview\n",
    "\n",
    "# Run it\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a4ecb35",
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutError",
     "evalue": "Timeout 30000ms exceeded.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTimeoutError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m     \u001b[38;5;28mprint\u001b[39m(text[:\u001b[32m1000\u001b[39m])  \u001b[38;5;66;03m# preview\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Just call it like this in a Jupyter notebook\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m main()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m     15\u001b[39m     url = \u001b[33m\"\u001b[39m\u001b[33mhttps://apidog.com/vi/blog/rag-deepseek-r1-ollama-vi/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     html = \u001b[38;5;28;01mawait\u001b[39;00m fetch_rendered_html(url)\n\u001b[32m     17\u001b[39m     soup = BeautifulSoup(html, \u001b[33m\"\u001b[39m\u001b[33mhtml.parser\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m     text = soup.get_text()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mfetch_rendered_html\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m      7\u001b[39m page = \u001b[38;5;28;01mawait\u001b[39;00m browser.new_page()\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m page.goto(url)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m page.wait_for_load_state(\u001b[33m'\u001b[39m\u001b[33mnetworkidle\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     10\u001b[39m content = \u001b[38;5;28;01mawait\u001b[39;00m page.content()\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m browser.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/RAG-Chatbot/venv/lib/python3.12/site-packages/playwright/async_api/_generated.py:9083\u001b[39m, in \u001b[36mPage.wait_for_load_state\u001b[39m\u001b[34m(self, state, timeout)\u001b[39m\n\u001b[32m   9031\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwait_for_load_state\u001b[39m(\n\u001b[32m   9032\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   9033\u001b[39m     state: typing.Optional[\n\u001b[32m   (...)\u001b[39m\u001b[32m   9037\u001b[39m     timeout: typing.Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   9038\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9039\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Page.wait_for_load_state\u001b[39;00m\n\u001b[32m   9040\u001b[39m \n\u001b[32m   9041\u001b[39m \u001b[33;03m    Returns when the required load state has been reached.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   9079\u001b[39m \u001b[33;03m        `page.set_default_timeout()` methods.\u001b[39;00m\n\u001b[32m   9080\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   9082\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping.from_maybe_impl(\n\u001b[32m-> \u001b[39m\u001b[32m9083\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._impl_obj.wait_for_load_state(state=state, timeout=timeout)\n\u001b[32m   9084\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/RAG-Chatbot/venv/lib/python3.12/site-packages/playwright/_impl/_page.py:568\u001b[39m, in \u001b[36mPage.wait_for_load_state\u001b[39m\u001b[34m(self, state, timeout)\u001b[39m\n\u001b[32m    563\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwait_for_load_state\u001b[39m(\n\u001b[32m    564\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    565\u001b[39m     state: Literal[\u001b[33m\"\u001b[39m\u001b[33mdomcontentloaded\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mload\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnetworkidle\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    566\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    567\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m568\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._main_frame.wait_for_load_state(**locals_to_params(\u001b[38;5;28mlocals\u001b[39m()))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/RAG-Chatbot/venv/lib/python3.12/site-packages/playwright/_impl/_frame.py:243\u001b[39m, in \u001b[36mFrame.wait_for_load_state\u001b[39m\u001b[34m(self, state, timeout)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwait_for_load_state\u001b[39m(\n\u001b[32m    239\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    240\u001b[39m     state: Literal[\u001b[33m\"\u001b[39m\u001b[33mdomcontentloaded\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mload\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnetworkidle\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    241\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    242\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait_for_load_state_impl(state, timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/RAG-Chatbot/venv/lib/python3.12/site-packages/playwright/_impl/_frame.py:271\u001b[39m, in \u001b[36mFrame._wait_for_load_state_impl\u001b[39m\u001b[34m(self, state, timeout)\u001b[39m\n\u001b[32m    264\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m actual_state == state\n\u001b[32m    266\u001b[39m     waiter.wait_for_event(\n\u001b[32m    267\u001b[39m         \u001b[38;5;28mself\u001b[39m._event_emitter,\n\u001b[32m    268\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mloadstate\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    269\u001b[39m         handle_load_state_event,\n\u001b[32m    270\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m waiter.result()\n",
      "\u001b[31mTimeoutError\u001b[39m: Timeout 30000ms exceeded."
     ]
    }
   ],
   "source": [
    "from playwright.async_api import async_playwright\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "async def fetch_rendered_html(url):\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(url)\n",
    "        await page.wait_for_load_state('networkidle')\n",
    "        content = await page.content()\n",
    "        await browser.close()\n",
    "        return content\n",
    "\n",
    "async def main():\n",
    "    url = \"https://apidog.com/vi/blog/rag-deepseek-r1-ollama-vi/\"\n",
    "    html = await fetch_rendered_html(url)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    text = soup.get_text()\n",
    "    print(text[:1000])  # preview\n",
    "\n",
    "# Just call it like this in a Jupyter notebook\n",
    "await main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
